{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a4f11431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26c2adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    HAS_SENTENCE_TRANSFORMERS = True\n",
    "except ImportError:\n",
    "    HAS_SENTENCE_TRANSFORMERS = False\n",
    "USE_SENTENCE_TRANSFORMERS = False  # Defina True para habilitar embeddings BERT (mais lento)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "ARTIFACT_DIR = Path(\"poc_artifacts\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)\n",
    "random.seed(RNG_SEED)\n",
    "\n",
    "# Ajuste opcional para acelerar testes; use None para todo o dataset\n",
    "SAMPLE_LIMIT = None\n",
    "\n",
    "# Número de vizinhos utilizado na votação do Annoy\n",
    "MODEL_SAMPLE_SIZE = 12000\n",
    "ANNOY_TOP_K = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51b10aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(value: str) -> str:\n",
    "    if not isinstance(value, str):\n",
    "        return \"\"\n",
    "    name = value.lower()\n",
    "    name = re.sub(r\"\\(.*?\\)|\\[.*?]\", \"\", name)\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    return re.sub(r\"\\s+\", \" \", name).strip()\n",
    "\n",
    "\n",
    "def load_raw_sources(data_dir: Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    steam_path = data_dir / \"steam-games-complete-dataset.csv\"\n",
    "    amazon_path = data_dir / \"meta_Video_Games.json\"\n",
    "    if not steam_path.exists():\n",
    "        raise FileNotFoundError(f\"Steam dataset not found: {steam_path}\")\n",
    "    if not amazon_path.exists():\n",
    "        raise FileNotFoundError(f\"Amazon dataset not found: {amazon_path}\")\n",
    "    steam_df = pd.read_csv(steam_path)\n",
    "    amazon_df = pd.read_json(amazon_path, lines=True, convert_dates=False)\n",
    "    return steam_df, amazon_df\n",
    "\n",
    "\n",
    "def join_sources(steam_df: pd.DataFrame, amazon_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    steam = steam_df.copy()\n",
    "    amazon = amazon_df.copy()\n",
    "\n",
    "    steam[\"normalized_name\"] = steam[\"name\"].apply(normalize_name)\n",
    "    amazon[\"normalized_name\"] = amazon[\"title\"].apply(normalize_name)\n",
    "\n",
    "    for col in [\"name\", \"url\", \"genre\", \"popular_tags\", \"reviews\", \"image_url\"]:\n",
    "        if col not in steam.columns:\n",
    "            steam[col] = \"Unknown\"\n",
    "\n",
    "    steam = steam[[\n",
    "        \"normalized_name\",\n",
    "        \"name\",\n",
    "        \"url\",\n",
    "        \"genre\",\n",
    "        \"popular_tags\",\n",
    "        \"reviews\",\n",
    "        \"image_url\",\n",
    "    ]].dropna(subset=[\"normalized_name\"])\n",
    "    steam = steam[steam[\"normalized_name\"] != \"\"]\n",
    "\n",
    "    amazon = amazon[[\"normalized_name\", \"title\", \"category\"]].dropna(subset=[\"normalized_name\"])\n",
    "    amazon = amazon[amazon[\"normalized_name\"] != \"\"]\n",
    "\n",
    "    merged = pd.merge(steam, amazon, on=\"normalized_name\", how=\"outer\", suffixes=(\"_steam\", \"_amazon\"))\n",
    "    merged[\"title\"] = merged[\"title\"].fillna(merged[\"name\"]).fillna(\"Unknown\")\n",
    "    merged[\"name\"] = merged[\"name\"].fillna(\"Unknown\")\n",
    "    merged[\"genre\"] = merged[\"genre\"].fillna(\"Unknown\")\n",
    "    merged[\"popular_tags\"] = merged[\"popular_tags\"].fillna(\"[]\")\n",
    "    merged[\"category\"] = merged[\"category\"].fillna(\"[]\")\n",
    "    merged[\"url\"] = merged[\"url\"].fillna(\"Unknown\")\n",
    "    merged[\"reviews\"] = merged[\"reviews\"].fillna(\"Unknown\")\n",
    "    merged[\"image_url\"] = merged[\"image_url\"].fillna(\"Unknown\")\n",
    "    merged[\"tags\"] = merged[\"popular_tags\"]\n",
    "    merged[\"categoria\"] = merged[\"category\"]\n",
    "    merged = merged.drop_duplicates(subset=[\"normalized_name\"]).reset_index(drop=True)\n",
    "    return merged\n",
    "\n",
    "\n",
    "GENRE_MAPPING: Dict[str, List[str]] = {\n",
    "    \"Action\": [\"Action\", \"Shooter\", \"Fighting\", \"Beat em up\"],\n",
    "    \"Adventure\": [\"Adventure\", \"Point & Click\"],\n",
    "    \"RPG\": [\"RPG\", \"JRPG\", \"CRPG\", \"Roguelike\"],\n",
    "    \"Strategy\": [\"Strategy\", \"RTS\", \"Turn-Based Strategy\", \"Grand Strategy\"],\n",
    "    \"Simulation\": [\"Simulation\", \"City Builder\", \"Management\"],\n",
    "    \"Sports\": [\"Sports\", \"Racing\", \"Football\", \"Basketball\"],\n",
    "    \"Indie\": [\"Indie\", \"Casual\"],\n",
    "}\n",
    "\n",
    "\n",
    "def clean_genre(genre_str: str) -> str:\n",
    "    if not isinstance(genre_str, str) or genre_str == \"Unknown\":\n",
    "        return \"Other\"\n",
    "    for main_genre, variants in GENRE_MAPPING.items():\n",
    "        for variant in variants:\n",
    "            if variant.lower() in genre_str.lower():\n",
    "                return main_genre\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def parse_json_field_improved(field) -> List[str]:\n",
    "    if field is None or (isinstance(field, float) and np.isnan(field)):\n",
    "        return []\n",
    "    if isinstance(field, list):\n",
    "        data = field\n",
    "    elif isinstance(field, str):\n",
    "        if field.strip().lower() == \"unknown\":\n",
    "            return []\n",
    "        try:\n",
    "            loaded = json.loads(field)\n",
    "            data = loaded if isinstance(loaded, list) else [loaded]\n",
    "        except json.JSONDecodeError:\n",
    "            data = [field]\n",
    "    else:\n",
    "        data = [field]\n",
    "\n",
    "    cleaned: List[str] = []\n",
    "    for item in data:\n",
    "        if not isinstance(item, str):\n",
    "            item = str(item)\n",
    "        stripped = item.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "        clean_item = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", stripped).strip().lower()\n",
    "        if len(clean_item) > 2:\n",
    "            cleaned.append(clean_item)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def create_game_description(row: pd.Series) -> str:\n",
    "    title = str(row.get(\"title\", \"\")) if row.get(\"title\", \"\") != \"Unknown\" else \"\"\n",
    "    genre = str(row.get(\"clean_genre\", \"\")) if row.get(\"clean_genre\", \"\") != \"Unknown\" else \"\"\n",
    "    tags = \" \".join(row.get(\"clean_tags\", []))\n",
    "    categoria = \" \".join(row.get(\"clean_categoria\", []))\n",
    "    description = f\"Title: {title}. Genre: {genre}. Tags: {tags}. Category: {categoria}.\"\n",
    "    return description.strip()\n",
    "\n",
    "\n",
    "MAIN_GENRES_ONEHOT = [\"Action\", \"Adventure\", \"Strategy\", \"RPG\", \"Simulation\", \"Sports\", \"Indie\", \"Other\"]\n",
    "MAIN_GENRES_LABEL = [\"Action\", \"Adventure\", \"Strategy\", \"RPG\", \"Simulation\"]\n",
    "\n",
    "\n",
    "def get_main_genre(genre_str: str) -> str:\n",
    "    if not isinstance(genre_str, str) or genre_str == \"Unknown\":\n",
    "        return \"Other\"\n",
    "    for genre in MAIN_GENRES_LABEL:\n",
    "        if genre.lower() in genre_str.lower():\n",
    "            return genre\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def prepare_games_dataframe(steam_df: pd.DataFrame, amazon_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    merged = join_sources(steam_df, amazon_df)\n",
    "    games = merged.copy()\n",
    "    games[\"clean_genre\"] = games[\"genre\"].apply(clean_genre)\n",
    "    games[\"clean_tags\"] = games[\"tags\"].apply(parse_json_field_improved)\n",
    "    games[\"clean_categoria\"] = games[\"categoria\"].apply(parse_json_field_improved)\n",
    "    games[\"description\"] = games.apply(create_game_description, axis=1)\n",
    "    games[\"title\"] = games[\"title\"].replace(\"Unknown\", np.nan).fillna(games[\"name\"]).fillna(\"Unknown\")\n",
    "    for col in [\"title\", \"name\", \"url\", \"reviews\", \"genre\", \"image_url\"]:\n",
    "        games[col] = games[col].astype(str)\n",
    "    games.reset_index(drop=True, inplace=True)\n",
    "    return games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41b31fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelMetrics:\n",
    "    name: str\n",
    "    balanced_accuracy: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    silhouette: Optional[float]\n",
    "    confusion: np.ndarray\n",
    "    label_names: List[str]\n",
    "    extras: Optional[Dict[str, float]] = None\n",
    "\n",
    "\n",
    "def build_feature_matrices(games_df: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
    "    annoy_corpus = (\n",
    "        games_df[\"title\"].fillna(\"\").astype(str)\n",
    "        + \" \"\n",
    "        + games_df[\"genre\"].fillna(\"\").astype(str)\n",
    "        + \" \"\n",
    "        + games_df[\"clean_tags\"].apply(lambda tags: \" \".join(tags)).astype(str)\n",
    "        + \" \"\n",
    "        + games_df[\"clean_categoria\"].apply(lambda cats: \" \".join(cats)).astype(str)\n",
    "    )\n",
    "    annoy_vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000, min_df=5)\n",
    "    annoy_matrix = annoy_vectorizer.fit_transform(annoy_corpus).toarray().astype(np.float32)\n",
    "\n",
    "    descriptions = games_df[\"description\"].fillna(\"\").tolist()\n",
    "    if HAS_SENTENCE_TRANSFORMERS and USE_SENTENCE_TRANSFORMERS:\n",
    "        embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        text_embeddings = embedding_model.encode(descriptions, show_progress_bar=False)\n",
    "    else:\n",
    "        tfidf_opt = TfidfVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            max_features=400,\n",
    "            min_df=2,\n",
    "            max_df=0.8,\n",
    "            ngram_range=(1, 2),\n",
    "        )\n",
    "        text_embeddings = tfidf_opt.fit_transform(descriptions).toarray()\n",
    "\n",
    "    numeric_features = pd.DataFrame(\n",
    "        {\n",
    "            \"title_len\": games_df[\"title\"].astype(str).str.len(),\n",
    "            \"has_url\": (games_df[\"url\"].astype(str) != \"Unknown\").astype(int),\n",
    "            \"tags_count\": games_df[\"clean_tags\"].apply(len),\n",
    "            \"categoria_count\": games_df[\"clean_categoria\"].apply(len),\n",
    "        }\n",
    "    )\n",
    "    for genre in MAIN_GENRES_ONEHOT:\n",
    "        numeric_features[f\"is_{genre.lower()}\"] = (games_df[\"clean_genre\"] == genre).astype(int)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    numeric_scaled = scaler.fit_transform(numeric_features.fillna(0))\n",
    "\n",
    "    combined_features = np.hstack([\n",
    "        text_embeddings.astype(np.float32),\n",
    "        numeric_scaled.astype(np.float32),\n",
    "    ])\n",
    "    return {\n",
    "        \"annoy_matrix\": annoy_matrix,\n",
    "        \"combined_features\": combined_features,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_classification_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_kmeans(features: np.ndarray, labels: np.ndarray, label_names: List[str], eval_indices: np.ndarray) -> ModelMetrics:\n",
    "    sample_size = min(2000, len(features))\n",
    "    sample_idx = np.random.choice(len(features), sample_size, replace=False)\n",
    "    sample_features = features[sample_idx]\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_k = 8\n",
    "    for k in range(6, 16):\n",
    "        temp_model = KMeans(n_clusters=k, random_state=RNG_SEED, n_init=5)\n",
    "        clusters = temp_model.fit_predict(sample_features)\n",
    "        if len(set(clusters)) <= 1:\n",
    "            continue\n",
    "        score = silhouette_score(sample_features, clusters)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    final_model = KMeans(n_clusters=best_k, random_state=RNG_SEED, n_init=5)\n",
    "    full_clusters = final_model.fit_predict(features)\n",
    "    sil_sample_size = min(1000, len(features))\n",
    "    sil_idx = np.random.choice(len(features), sil_sample_size, replace=False)\n",
    "    if len(set(full_clusters)) > 1:\n",
    "        silhouette = silhouette_score(features[sil_idx], full_clusters[sil_idx])\n",
    "    else:\n",
    "        silhouette = None\n",
    "\n",
    "    eval_features = features[eval_indices]\n",
    "    eval_labels = labels[eval_indices]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        eval_features,\n",
    "        eval_labels,\n",
    "        test_size=0.3,\n",
    "        random_state=RNG_SEED,\n",
    "    )\n",
    "\n",
    "    eval_model = KMeans(n_clusters=best_k, random_state=RNG_SEED, n_init=5)\n",
    "    train_clusters = eval_model.fit_predict(X_train)\n",
    "    cluster_to_label: Dict[int, int] = {}\n",
    "    for cluster_id in range(best_k):\n",
    "        mask = train_clusters == cluster_id\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        majority = Counter(y_train[mask]).most_common(1)[0][0]\n",
    "        cluster_to_label[cluster_id] = majority\n",
    "\n",
    "    default_label = Counter(y_train).most_common(1)[0][0]\n",
    "    test_clusters = eval_model.predict(X_test)\n",
    "    predictions = np.array([cluster_to_label.get(cid, default_label) for cid in test_clusters])\n",
    "\n",
    "    metrics = compute_classification_metrics(y_test, predictions)\n",
    "    cm = confusion_matrix(y_test, predictions, labels=list(range(len(label_names))))\n",
    "\n",
    "    return ModelMetrics(\n",
    "        name=f\"KMeans(k={best_k})\",\n",
    "        balanced_accuracy=metrics[\"balanced_accuracy\"],\n",
    "        precision=metrics[\"precision\"],\n",
    "        recall=metrics[\"recall\"],\n",
    "        f1=metrics[\"f1\"],\n",
    "        silhouette=silhouette,\n",
    "        confusion=cm,\n",
    "        label_names=label_names,\n",
    "        extras={\"best_k\": float(best_k)},\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_annoy(\n",
    "    annoy_matrix: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: List[str],\n",
    "    eval_indices: np.ndarray,\n",
    "    top_k: int = ANNOY_TOP_K,\n",
    ") -> ModelMetrics:\n",
    "    dims = annoy_matrix.shape[1]\n",
    "    annoy_index = AnnoyIndex(dims, metric=\"angular\")\n",
    "    for idx, vector in enumerate(annoy_matrix):\n",
    "        annoy_index.add_item(idx, vector.tolist())\n",
    "    annoy_index.build(50)\n",
    "\n",
    "    fallback_label = Counter(labels).most_common(1)[0][0]\n",
    "    predictions: List[int] = []\n",
    "    for idx in eval_indices:\n",
    "        neighbors = annoy_index.get_nns_by_item(idx, top_k + 1, include_distances=False)\n",
    "        neighbors = [n for n in neighbors if n != idx][:top_k]\n",
    "        if not neighbors:\n",
    "            predictions.append(fallback_label)\n",
    "            continue\n",
    "        neighbor_labels = labels[neighbors]\n",
    "        majority = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "        predictions.append(majority)\n",
    "\n",
    "    y_true = labels[eval_indices]\n",
    "    predictions_arr = np.array(predictions)\n",
    "    metrics = compute_classification_metrics(y_true, predictions_arr)\n",
    "    cm = confusion_matrix(y_true, predictions_arr, labels=list(range(len(label_names))))\n",
    "\n",
    "    return ModelMetrics(\n",
    "        name=f\"Annoy(top_k={top_k})\",\n",
    "        balanced_accuracy=metrics[\"balanced_accuracy\"],\n",
    "        precision=metrics[\"precision\"],\n",
    "        recall=metrics[\"recall\"],\n",
    "        f1=metrics[\"f1\"],\n",
    "        silhouette=None,\n",
    "        confusion=cm,\n",
    "        label_names=label_names,\n",
    "        extras={\"top_k\": float(top_k)},\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_metric_comparison(models: Iterable[ModelMetrics], output_path: Path) -> None:\n",
    "    metrics = [\"balanced_accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "    labels = [m.name for m in models]\n",
    "    values = {metric: [getattr(m, metric) for m in models] for metric in metrics}\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        plt.bar(x + idx * width, values[metric], width=width, label=metric.replace(\"_\", \" \").title())\n",
    "\n",
    "    plt.xticks(x + width * (len(metrics) - 1) / 2, labels, rotation=20)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Modelos vs. Métricas (macro)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion(cm: np.ndarray, label_names: List[str], title: str, output_path: Path) -> None:\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(label_names))\n",
    "    plt.xticks(tick_marks, label_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, label_names)\n",
    "\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            value = cm[i, j]\n",
    "            plt.text(\n",
    "                j,\n",
    "                i,\n",
    "                f\"{value}\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if value > thresh else \"black\",\n",
    "            )\n",
    "\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def write_metrics(metric: ModelMetrics) -> None:\n",
    "    output = {\n",
    "        \"model\": metric.name,\n",
    "        \"balanced_accuracy\": metric.balanced_accuracy,\n",
    "        \"precision_macro\": metric.precision,\n",
    "        \"recall_macro\": metric.recall,\n",
    "        \"f1_macro\": metric.f1,\n",
    "        \"silhouette\": metric.silhouette,\n",
    "        \"labels\": metric.label_names,\n",
    "        \"confusion_matrix\": metric.confusion.tolist(),\n",
    "        \"extras\": metric.extras or {},\n",
    "    }\n",
    "    safe_name = metric.name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"=\", \"\")\n",
    "    path = ARTIFACT_DIR / f\"metrics_{safe_name}.json\"\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dump(output, fp, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d1ebac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>best_k</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KMeans(k=8)</th>\n",
       "      <td>0.940222</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.940222</td>\n",
       "      <td>0.871932</td>\n",
       "      <td>0.634086</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annoy(top_k=15)</th>\n",
       "      <td>0.849357</td>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.849357</td>\n",
       "      <td>0.882125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 balanced_accuracy  precision_macro  recall_macro  f1_macro  \\\n",
       "model                                                                         \n",
       "KMeans(k=8)               0.940222         0.861111      0.940222  0.871932   \n",
       "Annoy(top_k=15)           0.849357         0.931599      0.849357  0.882125   \n",
       "\n",
       "                 silhouette  best_k  top_k  \n",
       "model                                       \n",
       "KMeans(k=8)        0.634086     8.0    NaN  \n",
       "Annoy(top_k=15)         NaN     NaN   15.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artefatos salvos em: /home/douglas/Documents/pi_big_data/recommender-service/etl/poc_artifacts\n",
      "Total de jogos considerados: 103400\n",
      "Tamanho da amostra nos modelos: 12000\n",
      "Sentence-Transformers habilitado: False\n"
     ]
    }
   ],
   "source": [
    "steam_df, amazon_df = load_raw_sources(DATA_DIR)\n",
    "games_df = prepare_games_dataframe(steam_df, amazon_df)\n",
    "\n",
    "if SAMPLE_LIMIT is not None and SAMPLE_LIMIT < len(games_df):\n",
    "    games_df = games_df.sample(SAMPLE_LIMIT, random_state=RNG_SEED).reset_index(drop=True)\n",
    "\n",
    "feature_data = build_feature_matrices(games_df)\n",
    "annoy_matrix = feature_data[\"annoy_matrix\"]\n",
    "combined_features = feature_data[\"combined_features\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "genre_labels = games_df[\"genre\"].apply(get_main_genre)\n",
    "genre_numeric = label_encoder.fit_transform(genre_labels)\n",
    "label_names = label_encoder.inverse_transform(np.arange(len(label_encoder.classes_))).tolist()\n",
    "\n",
    "model_sample_size = len(games_df) if MODEL_SAMPLE_SIZE is None else min(int(MODEL_SAMPLE_SIZE), len(games_df))\n",
    "\n",
    "sample_indices = np.random.choice(len(games_df), model_sample_size, replace=False)\n",
    "sample_features = combined_features[sample_indices]\n",
    "sample_annoy_matrix = annoy_matrix[sample_indices]\n",
    "sample_labels = genre_numeric[sample_indices]\n",
    "\n",
    "baseline_eval_size = min(1500, len(sample_features))\n",
    "baseline_eval_indices = np.random.choice(len(sample_features), baseline_eval_size, replace=False)\n",
    "\n",
    "kmeans_metrics = evaluate_kmeans(sample_features, sample_labels, label_names, baseline_eval_indices)\n",
    "annoy_metrics = evaluate_annoy(sample_annoy_matrix, sample_labels, label_names, baseline_eval_indices, top_k=ANNOY_TOP_K)\n",
    "\n",
    "metrics_list = [kmeans_metrics, annoy_metrics]\n",
    "\n",
    "plot_metric_comparison(metrics_list, ARTIFACT_DIR / \"metrics_comparison.png\")\n",
    "plot_confusion(\n",
    "    kmeans_metrics.confusion,\n",
    "    label_names,\n",
    "    f\"Matriz de Confusao - {kmeans_metrics.name}\",\n",
    "    ARTIFACT_DIR / \"confusion_kmeans.png\",\n",
    ")\n",
    "plot_confusion(\n",
    "    annoy_metrics.confusion,\n",
    "    label_names,\n",
    "    f\"Matriz de Confusao - {annoy_metrics.name}\",\n",
    "    ARTIFACT_DIR / \"confusion_annoy.png\",\n",
    ")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    write_metrics(metric)\n",
    "\n",
    "metrics_table = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"model\": m.name,\n",
    "            \"balanced_accuracy\": m.balanced_accuracy,\n",
    "            \"precision_macro\": m.precision,\n",
    "            \"recall_macro\": m.recall,\n",
    "            \"f1_macro\": m.f1,\n",
    "            \"silhouette\": m.silhouette,\n",
    "            **(m.extras or {}),\n",
    "        }\n",
    "        for m in metrics_list\n",
    "    ]\n",
    ").set_index(\"model\")\n",
    "display(metrics_table)\n",
    "print(f\"Artefatos salvos em: {ARTIFACT_DIR.resolve()}\")\n",
    "print(f\"Total de jogos considerados: {len(games_df)}\")\n",
    "print(f\"Tamanho da amostra nos modelos: {len(sample_features)}\")\n",
    "print(f\"Sentence-Transformers habilitado: {HAS_SENTENCE_TRANSFORMERS and USE_SENTENCE_TRANSFORMERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "daf97606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/douglas/Documents/pi_big_data/recommender-service/gamefinder-venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>best_k</th>\n",
       "      <th>top_k</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>linkage</th>\n",
       "      <th>affinity</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agglomerative(k=8)</th>\n",
       "      <td>0.810749</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>0.810749</td>\n",
       "      <td>0.796063</td>\n",
       "      <td>0.646912</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral(k=14)</th>\n",
       "      <td>0.691612</td>\n",
       "      <td>0.682334</td>\n",
       "      <td>0.691612</td>\n",
       "      <td>0.669960</td>\n",
       "      <td>0.193411</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nearest_neighbors</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    balanced_accuracy  precision_macro  recall_macro  \\\n",
       "model                                                                  \n",
       "Agglomerative(k=8)           0.810749         0.789562      0.810749   \n",
       "Spectral(k=14)               0.691612         0.682334      0.691612   \n",
       "\n",
       "                    f1_macro  silhouette  best_k  top_k  n_neighbors linkage  \\\n",
       "model                                                                          \n",
       "Agglomerative(k=8)  0.796063    0.646912     8.0    NaN          NaN    ward   \n",
       "Spectral(k=14)      0.669960    0.193411    14.0    NaN         20.0     NaN   \n",
       "\n",
       "                             affinity  metric  \n",
       "model                                          \n",
       "Agglomerative(k=8)                NaN     NaN  \n",
       "Spectral(k=14)      nearest_neighbors     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agglomerative & Spectral Clustering evaluation\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering\n",
    "\n",
    "columns_order = [\n",
    "    \"balanced_accuracy\",\n",
    "    \"precision_macro\",\n",
    "    \"recall_macro\",\n",
    "    \"f1_macro\",\n",
    "    \"silhouette\",\n",
    "    \"best_k\",\n",
    "    \"top_k\",\n",
    "    \"n_neighbors\",\n",
    "    \"linkage\",\n",
    "    \"affinity\",\n",
    "    \"metric\",\n",
    "]\n",
    "\n",
    "AGGLO_SAMPLE_SIZE = 4000\n",
    "SPECTRAL_SAMPLE_SIZE = 3000\n",
    "\n",
    "def _sanitize_model_name(name: str) -> str:\n",
    "    return (\n",
    "        name.replace(\" \", \"_\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"=\", \"\")\n",
    "        .replace(\",\", \"\")\n",
    "    )\n",
    "\n",
    "# Garantir que amostras existem (útil ao executar células isoladas)\n",
    "if 'sample_features' not in locals() or 'sample_labels' not in locals():\n",
    "    model_sample_size = len(games_df) if MODEL_SAMPLE_SIZE is None else min(int(MODEL_SAMPLE_SIZE), len(games_df))\n",
    "    sample_indices = np.random.choice(len(games_df), model_sample_size, replace=False)\n",
    "    sample_features = combined_features[sample_indices]\n",
    "    sample_annoy_matrix = annoy_matrix[sample_indices]\n",
    "    sample_labels = genre_numeric[sample_indices]\n",
    "\n",
    "def evaluate_agglomerative(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: List[str],\n",
    "    linkage: str = \"ward\",\n",
    ") -> ModelMetrics:\n",
    "    if len(features) < 2:\n",
    "        raise ValueError(\"É necessário pelo menos 2 jogos para Agglomerative Clustering.\")\n",
    "\n",
    "    train_size = min(AGGLO_SAMPLE_SIZE, len(features))\n",
    "    train_idx = np.random.choice(len(features), train_size, replace=False)\n",
    "    train_features = features[train_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "\n",
    "    candidate_ks = [k for k in range(6, 16) if k < len(train_features)]\n",
    "    if not candidate_ks:\n",
    "        candidate_ks = [max(2, len(train_features) - 1)]\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_k = candidate_ks[0]\n",
    "    for k in candidate_ks:\n",
    "        try:\n",
    "            model = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
    "            clusters = model.fit_predict(train_features)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if len(set(clusters)) <= 1:\n",
    "            continue\n",
    "        score = silhouette_score(train_features, clusters)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    final_model = AgglomerativeClustering(n_clusters=best_k, linkage=linkage)\n",
    "    cluster_labels = final_model.fit_predict(train_features)\n",
    "\n",
    "    fallback_label = Counter(train_labels).most_common(1)[0][0]\n",
    "    cluster_to_label: Dict[int, int] = {}\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        mask = cluster_labels == cluster_id\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        majority = Counter(train_labels[mask]).most_common(1)[0][0]\n",
    "        cluster_to_label[cluster_id] = majority\n",
    "\n",
    "    predictions = np.array([cluster_to_label.get(cid, fallback_label) for cid in cluster_labels])\n",
    "    metrics = compute_classification_metrics(train_labels, predictions)\n",
    "\n",
    "    silhouette = None\n",
    "    if len(set(cluster_labels)) > 1:\n",
    "        silhouette = silhouette_score(train_features, cluster_labels)\n",
    "\n",
    "    cm = confusion_matrix(train_labels, predictions, labels=list(range(len(label_names))))\n",
    "\n",
    "    return ModelMetrics(\n",
    "        name=f\"Agglomerative(k={best_k})\",\n",
    "        balanced_accuracy=metrics[\"balanced_accuracy\"],\n",
    "        precision=metrics[\"precision\"],\n",
    "        recall=metrics[\"recall\"],\n",
    "        f1=metrics[\"f1\"],\n",
    "        silhouette=silhouette,\n",
    "        confusion=cm,\n",
    "        label_names=label_names,\n",
    "        extras={\"best_k\": float(best_k), \"linkage\": linkage},\n",
    "    )\n",
    "\n",
    "def evaluate_spectral(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: List[str],\n",
    "    affinity: str = \"nearest_neighbors\",\n",
    "    n_neighbors: int = SPECTRAL_SAMPLE_SIZE // 6,\n",
    ") -> ModelMetrics:\n",
    "    if len(features) < 2:\n",
    "        raise ValueError(\"É necessário pelo menos 2 jogos para Spectral Clustering.\")\n",
    "\n",
    "    train_size = min(SPECTRAL_SAMPLE_SIZE, len(features))\n",
    "    train_idx = np.random.choice(len(features), train_size, replace=False)\n",
    "    train_features = features[train_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "\n",
    "    nn_sample = max(1, min(n_neighbors, train_features.shape[0] - 1))\n",
    "\n",
    "    candidate_ks = [k for k in range(6, 16) if k < len(train_features)]\n",
    "    if not candidate_ks:\n",
    "        candidate_ks = [max(2, len(train_features) - 1)]\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_k = candidate_ks[0]\n",
    "    for k in candidate_ks:\n",
    "        try:\n",
    "            model = SpectralClustering(\n",
    "                n_clusters=k,\n",
    "                random_state=RNG_SEED,\n",
    "                assign_labels=\"kmeans\",\n",
    "                affinity=affinity,\n",
    "                n_neighbors=nn_sample,\n",
    "            )\n",
    "            clusters = model.fit_predict(train_features)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if len(set(clusters)) <= 1:\n",
    "            continue\n",
    "        score = silhouette_score(train_features, clusters)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    nn_full = max(1, min(n_neighbors, train_features.shape[0] - 1))\n",
    "\n",
    "    final_model = SpectralClustering(\n",
    "        n_clusters=best_k,\n",
    "        random_state=RNG_SEED,\n",
    "        assign_labels=\"kmeans\",\n",
    "        affinity=affinity,\n",
    "        n_neighbors=nn_full,\n",
    "    )\n",
    "    cluster_labels = final_model.fit_predict(train_features)\n",
    "\n",
    "    fallback_label = Counter(train_labels).most_common(1)[0][0]\n",
    "    cluster_to_label: Dict[int, int] = {}\n",
    "    for cluster_id in np.unique(cluster_labels):\n",
    "        mask = cluster_labels == cluster_id\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        majority = Counter(train_labels[mask]).most_common(1)[0][0]\n",
    "        cluster_to_label[cluster_id] = majority\n",
    "\n",
    "    predictions = np.array([cluster_to_label.get(cid, fallback_label) for cid in cluster_labels])\n",
    "    metrics = compute_classification_metrics(train_labels, predictions)\n",
    "\n",
    "    silhouette = None\n",
    "    if len(set(cluster_labels)) > 1:\n",
    "        silhouette = silhouette_score(train_features, cluster_labels)\n",
    "\n",
    "    cm = confusion_matrix(train_labels, predictions, labels=list(range(len(label_names))))\n",
    "\n",
    "    return ModelMetrics(\n",
    "        name=f\"Spectral(k={best_k})\",\n",
    "        balanced_accuracy=metrics[\"balanced_accuracy\"],\n",
    "        precision=metrics[\"precision\"],\n",
    "        recall=metrics[\"recall\"],\n",
    "        f1=metrics[\"f1\"],\n",
    "        silhouette=silhouette,\n",
    "        confusion=cm,\n",
    "        label_names=label_names,\n",
    "        extras={\"best_k\": float(best_k), \"n_neighbors\": float(nn_full), \"affinity\": affinity},\n",
    "    )\n",
    "\n",
    "agglo_metrics = evaluate_agglomerative(sample_features, sample_labels, label_names, linkage=\"ward\")\n",
    "spectral_metrics = evaluate_spectral(sample_features, sample_labels, label_names, affinity=\"nearest_neighbors\", n_neighbors=20)\n",
    "additional_metrics = [agglo_metrics, spectral_metrics]\n",
    "metrics_list.extend(additional_metrics)\n",
    "\n",
    "for metric in additional_metrics:\n",
    "    safe_name = _sanitize_model_name(metric.name)\n",
    "    plot_confusion(\n",
    "        metric.confusion,\n",
    "        label_names,\n",
    "        f\"Matriz de Confusao - {metric.name}\",\n",
    "        ARTIFACT_DIR / f\"confusion_{safe_name}.png\",\n",
    "    )\n",
    "    write_metrics(metric)\n",
    "\n",
    "agglo_spectral_table = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"model\": m.name,\n",
    "            \"balanced_accuracy\": m.balanced_accuracy,\n",
    "            \"precision_macro\": m.precision,\n",
    "            \"recall_macro\": m.recall,\n",
    "            \"f1_macro\": m.f1,\n",
    "            \"silhouette\": m.silhouette,\n",
    "            **(m.extras or {}),\n",
    "        }\n",
    "        for m in additional_metrics\n",
    "    ]\n",
    ").set_index(\"model\").reindex(columns=columns_order)\n",
    "\n",
    "display(agglo_spectral_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2024e8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>best_k</th>\n",
       "      <th>top_k</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>linkage</th>\n",
       "      <th>affinity</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestNeighbors(top_k=15)</th>\n",
       "      <td>0.909476</td>\n",
       "      <td>0.902963</td>\n",
       "      <td>0.909476</td>\n",
       "      <td>0.905517</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cosine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            balanced_accuracy  precision_macro  recall_macro  \\\n",
       "model                                                                          \n",
       "NearestNeighbors(top_k=15)           0.909476         0.902963      0.909476   \n",
       "\n",
       "                            f1_macro silhouette  best_k  top_k  n_neighbors  \\\n",
       "model                                                                         \n",
       "NearestNeighbors(top_k=15)  0.905517       None     NaN   15.0          NaN   \n",
       "\n",
       "                            linkage  affinity  metric  \n",
       "model                                                  \n",
       "NearestNeighbors(top_k=15)      NaN       NaN  cosine  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Brute-force Nearest Neighbors evaluation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "NEAREST_TOP_K = ANNOY_TOP_K\n",
    "\n",
    "if 'sample_features' not in locals() or 'sample_labels' not in locals():\n",
    "    model_sample_size = len(games_df) if MODEL_SAMPLE_SIZE is None else min(int(MODEL_SAMPLE_SIZE), len(games_df))\n",
    "    sample_indices = np.random.choice(len(games_df), model_sample_size, replace=False)\n",
    "    sample_features = combined_features[sample_indices]\n",
    "    sample_annoy_matrix = annoy_matrix[sample_indices]\n",
    "    sample_labels = genre_numeric[sample_indices]\n",
    "\n",
    "def evaluate_exact_neighbors(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: List[str],\n",
    "    eval_indices: np.ndarray,\n",
    "    top_k: int = NEAREST_TOP_K,\n",
    "    metric: str = \"cosine\",\n",
    ") -> ModelMetrics:\n",
    "    if len(features) < 2:\n",
    "        raise ValueError(\"É necessário pelo menos 2 jogos para Nearest Neighbors.\")\n",
    "\n",
    "    n_neighbors = min(top_k + 1, len(features))\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, algorithm=\"auto\")\n",
    "    nn_model.fit(features)\n",
    "\n",
    "    fallback_label = Counter(labels).most_common(1)[0][0]\n",
    "    predictions: List[int] = []\n",
    "    for idx in eval_indices:\n",
    "        distances, neighbors = nn_model.kneighbors(features[idx][None, :], n_neighbors=n_neighbors)\n",
    "        neighbors = [n for n in neighbors[0] if n != idx][:top_k]\n",
    "        if not neighbors:\n",
    "            predictions.append(fallback_label)\n",
    "            continue\n",
    "        neighbor_labels = labels[neighbors]\n",
    "        majority = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "        predictions.append(majority)\n",
    "\n",
    "    y_true = labels[eval_indices]\n",
    "    predictions_arr = np.array(predictions)\n",
    "    metrics = compute_classification_metrics(y_true, predictions_arr)\n",
    "    cm = confusion_matrix(y_true, predictions_arr, labels=list(range(len(label_names))))\n",
    "\n",
    "    return ModelMetrics(\n",
    "        name=f\"NearestNeighbors(top_k={top_k})\",\n",
    "        balanced_accuracy=metrics[\"balanced_accuracy\"],\n",
    "        precision=metrics[\"precision\"],\n",
    "        recall=metrics[\"recall\"],\n",
    "        f1=metrics[\"f1\"],\n",
    "        silhouette=None,\n",
    "        confusion=cm,\n",
    "        label_names=label_names,\n",
    "        extras={\"top_k\": float(top_k), \"metric\": metric},\n",
    "    )\n",
    "\n",
    "nn_eval_size = min(1200, len(sample_features))\n",
    "nn_eval_indices = np.random.choice(len(sample_features), nn_eval_size, replace=False)\n",
    "\n",
    "nearest_metrics = evaluate_exact_neighbors(sample_features, sample_labels, label_names, nn_eval_indices)\n",
    "metrics_list.append(nearest_metrics)\n",
    "\n",
    "plot_confusion(\n",
    "    nearest_metrics.confusion,\n",
    "    label_names,\n",
    "    f\"Matriz de Confusao - {nearest_metrics.name}\",\n",
    "    ARTIFACT_DIR / f\"confusion_{_sanitize_model_name(nearest_metrics.name)}.png\",\n",
    ")\n",
    "write_metrics(nearest_metrics)\n",
    "\n",
    "nearest_table = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": nearest_metrics.name,\n",
    "        \"balanced_accuracy\": nearest_metrics.balanced_accuracy,\n",
    "        \"precision_macro\": nearest_metrics.precision,\n",
    "        \"recall_macro\": nearest_metrics.recall,\n",
    "        \"f1_macro\": nearest_metrics.f1,\n",
    "        \"silhouette\": nearest_metrics.silhouette,\n",
    "        **(nearest_metrics.extras or {}),\n",
    "    }\n",
    "]).set_index(\"model\").reindex(columns=columns_order)\n",
    "\n",
    "display(nearest_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gamefinder-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
